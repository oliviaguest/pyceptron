\documentclass[mathserif]{beamer}
% \usepackage{eulervm}
\usepackage{default}
\usepackage{caption}
\usepackage{booktabs,mathptmx,siunitx}
\graphicspath{{img/}}
\captionsetup{font=scriptsize,labelfont=scriptsize}
\begin{document}


\begin{frame}
% % \frametitle{What is programming?}
% \framesubtitle{It is like use using any other language!}
% 
% ``Getting an education was a bit like a communicable sexual disease. It made you unsuitable for a lot of jobs and then you had the urge to pass it on.''
% \\ \
\centering\Huge Welcome to the computational cognitive modelling workshop! 
\vfill \huge
\centering\textbf{Part 2: Artificial neural networks} \normalsize
\vfill
% \textit{Olivia Guest \hfill  Chris Brand \\  \ Nick Sexton \hfill Nicole Cruz De Echeverria Loebell } 
% -- \textit{Terry Pratchett}
\end{frame}

\begin{frame}
% % \frametitle{What is programming?}
% \framesubtitle{It is like use using any other language!}
% 
% ``Getting an education was a bit like a communicable sexual disease. It made you unsuitable for a lot of jobs and then you had the urge to pass it on.''
% \\ \
\vfill \Huge
\centering Part 2: \textbf{Artificial neural networks} \large
\vfill
\textit{
Olivia Guest \hfill  Chris Brand 
\vspace{0.5cm} \\ \ 
Nick Sexton \hfill Nicole Cruz De Echeverria Loebell } 
% -- \textit{Terry Pratchett}
\end{frame}


\begin{frame}
\frametitle{What is a neural network?}
\framesubtitle{A mathematical model}
\begin{itemize}
\item Inspired by the nervous system \\ \
 \item A set of \emph{units}, connected by \emph{weights} \\ \
\item The network \emph{runs} by passing \emph{activations} from the \emph{input} (to the \emph{hidden}) to the \emph{output} units \\ \
\end{itemize}
\end{frame}
\begin{frame}
\frametitle{What is a neural network?}
\framesubtitle{A mathematical model}
\begin{figure}
 \centering
 \includegraphics[width=0.6\linewidth]{./fig/3-layer.pdf}
 % 3-layer.pdf: 236x271 pixel, 72dpi, 8.33x9.56 cm, bb=0 0 236 271
 \caption{Glosser.ca / CC-BY-SA-3.0}
\end{figure}
\end{frame}




\begin{frame}
\frametitle{Why use artificial neural networks for modelling?}
\framesubtitle{Some aspects of their behaviour are like their namesake!}
\begin{itemize}
\item Learn pretty much any input-output data \\ \
 \item Uncover rules on their own about data  \\ \
\item Generalise what from what they have learnt \\ \
\item Cope well with noise and damage \\ \
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{How does an artificial neural network run?}
\framesubtitle{By using maths, predictably!}
  \begin{columns}[T]
    \begin{column}{.5\textwidth}
%      \begin{block}{Run network}
Input units are set to a \emph{pattern} \\
\ \\
Calculate hidden units' states: \\
\ \\
\begin{tabular}{r S[tabformat=3.2] r}% syntax for siunitx v2; for v1 use "tabformat"
 $1 \times 0.5 =$ & $0.5$ &\\
 $1 \times 0.0 =$ & $0.0$ &\\
 $0 \times 0.8 =$ & $0.0$ & +\\
 \hline
 & $0.5$ &
\end{tabular}

Same for output units: \\
\ \\
\begin{tabular}{r S[tabformat=3.2] r}% syntax for siunitx v2; for v1 use "tabformat"
 $0.5 \times 0.25 =$ & $0.125$ &\\
 $0.3 \times 1.5  =$ & $0.45$ &\\
 $1.6 \times -0.3 =$ & $-0.48$ &\\
 $-0.4 \times 1.1 =$ & $-0.44$ & + \\
 \hline
 & $-0.345$ & 
\end{tabular}
% \end{block}
    \end{column}
    \begin{column}{.5\textwidth}
%     \begin{block}{}
% Your image included here
\begin{figure}
 \centering
 \includegraphics[width=\linewidth]{./fig/3-layer_propagate.pdf}
  \caption{Glosser.ca / CC-BY-SA-3.0}
\end{figure}
%     \end{block}
    \end{column}
  \end{columns}
\end{frame}




\begin{frame}
\frametitle{How does an artificial neural network run?}
\framesubtitle{By using maths, predictably!}
  \begin{columns}[T]
    \begin{column}{.5\textwidth}
     \ \\
     \ \\
     
But we/programmers are lazy:
\begin{equation*}
a_i = \sum_1^N x_j \times w_{ji}
\end{equation*}
where $a_i$ is the unit whose state we want to calculate, $N$ are the units on the previous layer, and $w_{ji}$ is the weight on the connection between $i$ and $j$.

% Which means, to calculate, e.g., $a_1$ multiply all the states in layer before with the incoming weight and then add them up. So in our case all the $x_1~...~x_3$ because $N = 3$.  
% \end{block}
    \end{column}
    \begin{column}{.5\textwidth}
%     \begin{block}{}
% Your image included here
	\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{./fig/3-layer_maths.pdf}
	  \caption{Glosser.ca / CC-BY-SA-3.0}
	\end{figure}
%     \end{block}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}
\frametitle{How do networks learn?}
\framesubtitle{Cunning!}
\begin{itemize}
\item Many options: Hebbian learning, back-propagation of error, Boltzmann machine learning, self-organising map algorithm, etc. \\ \

\item All learning algorithms work by changing the connection weights \\ \

\item Learning can be divided into \emph{supervised}, \emph{unsupervised}, and \emph{reinforcement} \\ \ \end{itemize}
\end{frame}

\begin{frame}
\frametitle{Hebbian Learning}
\framesubtitle{A simple training rule}

\begin{quotation}Cells that fire together, wire together\end{quotation} 
\hfill Carla Shatz 

\vfill

\begin{quotation}The general idea is an old one, that any two cells or systems of cells that are repeatedly active at the same time will tend to become 'associated', so that activity in one facilitates activity in the other.\end{quotation} 
\hfill(Hebb 1949, p. 70)




\end{frame}


\begin{frame}
\frametitle{Hebbian Learning}
\framesubtitle{Cells that fire together, wire together}
  \begin{columns}[T]
    \begin{column}{.5\textwidth}
      \begin{equation*}
      w_{ij} = \sum^N_i \eta  x_i x_j
      \end{equation*}

    \end{column}
    \begin{column}{.5\textwidth}
%     \begin{block}{}
% Your image included here
\begin{figure}
 \centering
 \includegraphics[width=\linewidth]{./fig/3-layer.pdf}
  \caption{Glosser.ca / CC-BY-SA-3.0}
\end{figure}
%     \end{block}
    \end{column}
  \end{columns}
\end{frame}



\end{document}
